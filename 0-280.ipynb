{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:49:47.899615Z",
     "iopub.status.busy": "2025-12-14T15:49:47.899379Z",
     "iopub.status.idle": "2025-12-14T15:50:05.332227Z",
     "shell.execute_reply": "2025-12-14T15:50:05.331595Z",
     "shell.execute_reply.started": "2025-12-14T15:49:47.899596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "from collections import defaultdict\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:50:05.334330Z",
     "iopub.status.busy": "2025-12-14T15:50:05.333951Z",
     "iopub.status.idle": "2025-12-14T15:50:05.338885Z",
     "shell.execute_reply": "2025-12-14T15:50:05.338301Z",
     "shell.execute_reply.started": "2025-12-14T15:50:05.334312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# KAGGLE PATH CONFIG\n",
    "BASE_INPUT = \"/kaggle/input\"\n",
    "CHECKPOINT_PATH = f\"{BASE_INPUT}/checkpoint-310-cafa6/pytorch/default/1\"\n",
    "TRAIN_TERMS_PATH = (\n",
    "    f\"{BASE_INPUT}/cafa-6-protein-function-prediction/Train/train_terms.tsv\"\n",
    ")\n",
    "TRAIN_SEQUENCES_PATH = (\n",
    "    f\"{BASE_INPUT}/cafa-6-protein-function-prediction/Train/train_sequences.fasta\"\n",
    ")\n",
    "TEST_SEQUENCES_PATH = (\n",
    "    f\"{BASE_INPUT}/cafa-6-protein-function-prediction/Test/testsuperset.fasta\"\n",
    ")\n",
    "\n",
    "PROT_EMBEDS = f\"{BASE_INPUT}/protein-embeddings/protein_embeddings.npy\"\n",
    "PIDS = f\"{BASE_INPUT}/protein-embeddings/protein_id.csv\"\n",
    "\n",
    "OBO_PATH = (\n",
    "    f\"{BASE_INPUT}/cafa-6-protein-function-prediction/Train/go-basic.obo\"\n",
    ")\n",
    "GOA_PATH = f\"{BASE_INPUT}/protein-go-annotations/goa_uniprot_all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:50:05.339980Z",
     "iopub.status.busy": "2025-12-14T15:50:05.339733Z",
     "iopub.status.idle": "2025-12-14T15:50:13.719425Z",
     "shell.execute_reply": "2025-12-14T15:50:13.718642Z",
     "shell.execute_reply.started": "2025-12-14T15:50:05.339963Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "protein_ids = pd.read_csv(PIDS)[\"protein_id\"].tolist()\n",
    "embeddings = np.load(PROT_EMBEDS, mmap_mode=\"r\")\n",
    "\n",
    "assert len(protein_ids) == embeddings.shape[0], \\\n",
    "    \"protein_id count does not match embedding rows\"\n",
    "\n",
    "print(f\"Loaded {embeddings.shape[0]} embeddings of dimension {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:50:13.720524Z",
     "iopub.status.busy": "2025-12-14T15:50:13.720230Z",
     "iopub.status.idle": "2025-12-14T15:50:16.552894Z",
     "shell.execute_reply": "2025-12-14T15:50:16.552312Z",
     "shell.execute_reply.started": "2025-12-14T15:50:13.720498Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def parse_fasta(fasta_file):\n",
    "    sequences = {}\n",
    "    current_id, current_seq = None, []\n",
    "\n",
    "    with open(fasta_file) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            if line.startswith(\">\"):\n",
    "                if current_id is not None:\n",
    "                    sequences[current_id] = \"\".join(current_seq)\n",
    "\n",
    "                header = line[1:]\n",
    "                current_id = header.split(\"|\")[1] if \"|\" in header else header.split()[0]\n",
    "                current_seq = []\n",
    "            else:\n",
    "                current_seq.append(line)\n",
    "\n",
    "        if current_id is not None:\n",
    "            sequences[current_id] = \"\".join(current_seq)\n",
    "\n",
    "    return sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:50:16.553768Z",
     "iopub.status.busy": "2025-12-14T15:50:16.553571Z",
     "iopub.status.idle": "2025-12-14T15:50:17.088914Z",
     "shell.execute_reply": "2025-12-14T15:50:17.088305Z",
     "shell.execute_reply.started": "2025-12-14T15:50:16.553752Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def parse_obo(go_obo_path):\n",
    "    parents = defaultdict(set)\n",
    "    children = defaultdict(set)\n",
    "    obsolete = set()\n",
    "\n",
    "    with open(go_obo_path) as f:\n",
    "        cur_id = None\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line == \"[Term]\":\n",
    "                cur_id = None\n",
    "            elif line.startswith(\"id: \"):\n",
    "                cur_id = line.split(\"id: \")[1]\n",
    "            elif line.startswith(\"is_obsolete: true\"):\n",
    "                obsolete.add(cur_id)\n",
    "            elif line.startswith(\"is_a: \") and cur_id:\n",
    "                pid = line.split()[1]\n",
    "                parents[cur_id].add(pid)\n",
    "                children[pid].add(cur_id)\n",
    "            elif line.startswith(\"relationship: part_of \") and cur_id:\n",
    "                pid = line.split()[2]\n",
    "                parents[cur_id].add(pid)\n",
    "                children[pid].add(cur_id)\n",
    "\n",
    "    for o in obsolete:\n",
    "        parents.pop(o, None)\n",
    "        children.pop(o, None)\n",
    "\n",
    "    return parents, children\n",
    "def get_all_ancestors(term, go_parents, cache=None):\n",
    "    if cache is None:\n",
    "        cache = {}\n",
    "    if term in cache:\n",
    "        return cache[term]\n",
    "    \n",
    "    ancestors = set()\n",
    "    stack = [term]\n",
    "    while stack:\n",
    "        cur = stack.pop()\n",
    "        for parent in go_parents.get(cur, []):\n",
    "            if parent not in ancestors:\n",
    "                ancestors.add(parent)\n",
    "                stack.append(parent)\n",
    "    \n",
    "    cache[term] = ancestors\n",
    "    return ancestors\n",
    "\n",
    "def get_all_descendants(term, go_children, cache=None):\n",
    "    if cache is None:\n",
    "        cache = {}\n",
    "    if term in cache:\n",
    "        return cache[term]\n",
    "    \n",
    "    descendants = set()\n",
    "    stack = [term]\n",
    "    while stack:\n",
    "        cur = stack.pop()\n",
    "        for child in go_children.get(cur, []):\n",
    "            if child not in descendants:\n",
    "                descendants.add(child)\n",
    "                stack.append(child)\n",
    "    \n",
    "    cache[term] = descendants\n",
    "    return descendants\n",
    "\n",
    "go_parents, go_children = parse_obo(OBO_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:50:17.090037Z",
     "iopub.status.busy": "2025-12-14T15:50:17.089683Z",
     "iopub.status.idle": "2025-12-14T15:50:17.102588Z",
     "shell.execute_reply": "2025-12-14T15:50:17.101932Z",
     "shell.execute_reply.started": "2025-12-14T15:50:17.090010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# GOA NEGATIVE PROPAGATION\n",
    "def load_goa_and_build_negative_keys(goa_path, go_children):\n",
    "    \"\"\"\n",
    "    Load GOA annotations and build:\n",
    "    1. negative_keys: protein-GO pairs to REMOVE (NOT + descendants)\n",
    "    2. goa_ground_truth: positive annotations to ADD with score 1.0\n",
    "    \"\"\"\n",
    "    if not os.path.exists(goa_path):\n",
    "        print(f\"[WARNING] GOA file not found at {goa_path}, skipping negative propagation\")\n",
    "        return set(), None\n",
    "\n",
    "    print(f\"Loading GOA annotations from {goa_path}...\")\n",
    "    goa_df = (\n",
    "        pd.read_csv(goa_path)\n",
    "        .drop_duplicates(subset=['protein_id', 'go_term', 'qualifier'])\n",
    "    )\n",
    "    print(f\"Loaded {len(goa_df)} GOA annotations\")\n",
    "\n",
    "    # NEGATIVE ANNOTATIONS \n",
    "    print(\"Extracting negative annotations (NOT)...\")\n",
    "    neg_df = goa_df[goa_df['qualifier'].str.contains('NOT', na=False)]\n",
    "    negative_by_protein = (\n",
    "        neg_df.groupby('protein_id')['go_term']\n",
    "        .apply(set)\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    print(\"Propagating negative annotations to descendants...\")\n",
    "    desc_cache = {}\n",
    "    negative_keys = set()\n",
    "\n",
    "    for protein, terms in tqdm(negative_by_protein.items(), desc=\"Propagating negatives\"):\n",
    "        all_terms = set(terms)\n",
    "        for term in terms:\n",
    "            all_terms.update(get_all_descendants(term, go_children, desc_cache))\n",
    "\n",
    "        for term in all_terms:\n",
    "            negative_keys.add(f\"{protein}_{term}\")\n",
    "\n",
    "    print(f\"Total unique negative protein-GO pairs: {len(negative_keys)}\")\n",
    "\n",
    "    # POSITIVE ANNOTATIONS\n",
    "    print(\"Extracting positive GOA ground truth...\")\n",
    "    pos_df = goa_df[~goa_df['qualifier'].str.contains('NOT', na=False)]\n",
    "    pos_df = pos_df[['protein_id', 'go_term']].drop_duplicates()\n",
    "\n",
    "    pos_df['pred_key'] = pos_df['protein_id'].astype(str) + '_' + pos_df['go_term'].astype(str)\n",
    "    pos_df = pos_df[~pos_df['pred_key'].isin(negative_keys)]\n",
    "\n",
    "    pos_df = pos_df.drop(columns='pred_key')\n",
    "    pos_df['score'] = 1.0\n",
    "\n",
    "    print(f\"Total positive GOA ground truth pairs: {len(pos_df)}\")\n",
    "\n",
    "    return negative_keys, pos_df\n",
    "\n",
    "\n",
    "def propagate_predictions(predictions_df, go_parents):\n",
    "    print(\"Propagating predictions to ancestor GO terms...\")\n",
    "\n",
    "    ancestor_cache = {}\n",
    "    propagated_rows = []\n",
    "\n",
    "    for pid, group in tqdm(predictions_df.groupby('pid'), desc=\"Propagating\"):\n",
    "        term_scores = {}\n",
    "\n",
    "        for row in group.itertuples(index=False):\n",
    "            term, score = row.term, row.p\n",
    "\n",
    "            # Original term\n",
    "            term_scores[term] = max(term_scores.get(term, 0.0), score)\n",
    "\n",
    "            # Ancestors\n",
    "            for ancestor in get_all_ancestors(term, go_parents, ancestor_cache):\n",
    "                term_scores[ancestor] = max(term_scores.get(ancestor, 0.0), score)\n",
    "\n",
    "        propagated_rows.extend(\n",
    "            {'pid': pid, 'term': t, 'p': s}\n",
    "            for t, s in term_scores.items()\n",
    "        )\n",
    "\n",
    "    propagated_df = pd.DataFrame(propagated_rows)\n",
    "\n",
    "    print(f\"Before propagation: {len(predictions_df)} predictions\")\n",
    "    print(f\"After propagation: {len(propagated_df)} predictions\")\n",
    "\n",
    "    return propagated_df\n",
    "\n",
    "\n",
    "def apply_negative_propagation(predictions_df, negative_keys):\n",
    "    if not negative_keys:\n",
    "        return predictions_df\n",
    "\n",
    "    before = len(predictions_df)\n",
    "\n",
    "    mask = (\n",
    "        predictions_df['pid'].astype(str)\n",
    "        + '_'\n",
    "        + predictions_df['term'].astype(str)\n",
    "    ).isin(negative_keys)\n",
    "\n",
    "    predictions_df = predictions_df.loc[~mask].copy()\n",
    "\n",
    "    after = len(predictions_df)\n",
    "    print(f\"Removed {before - after} negative predictions ({before} -> {after})\")\n",
    "\n",
    "    return predictions_df\n",
    "\n",
    "def add_goa_ground_truth(predictions_df, goa_positive_df):\n",
    "    \"\"\"Add GOA ground truth annotations with score 1.0\"\"\"\n",
    "    if goa_positive_df is None or goa_positive_df.empty:\n",
    "        return predictions_df\n",
    "\n",
    "    test_proteins = set(predictions_df['pid'].unique())\n",
    "\n",
    "    goa_for_test = (\n",
    "        goa_positive_df[goa_positive_df['protein_id'].isin(test_proteins)]\n",
    "        .rename(columns={\n",
    "            'protein_id': 'pid',\n",
    "            'go_term': 'term',\n",
    "            'score': 'p'\n",
    "        })[['pid', 'term', 'p']]\n",
    "    )\n",
    "\n",
    "    print(f\"Found {len(goa_for_test)} GOA annotations for test proteins\")\n",
    "\n",
    "    combined = pd.concat([predictions_df, goa_for_test], ignore_index=True)\n",
    "    combined = combined.groupby(['pid', 'term'], as_index=False)['p'].max()\n",
    "\n",
    "    print(f\"After adding GOA: {len(predictions_df)} -> {len(combined)} predictions\")\n",
    "\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:50:17.105069Z",
     "iopub.status.busy": "2025-12-14T15:50:17.104730Z",
     "iopub.status.idle": "2025-12-14T15:50:22.937075Z",
     "shell.execute_reply": "2025-12-14T15:50:22.936205Z",
     "shell.execute_reply.started": "2025-12-14T15:50:17.105053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "negative_keys, goa_positive_df = load_goa_and_build_negative_keys(GOA_PATH, go_children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:50:22.939185Z",
     "iopub.status.busy": "2025-12-14T15:50:22.938782Z",
     "iopub.status.idle": "2025-12-14T15:50:22.946737Z",
     "shell.execute_reply": "2025-12-14T15:50:22.946206Z",
     "shell.execute_reply.started": "2025-12-14T15:50:22.939153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "  class ProtDataset(Dataset):\n",
    "    def __init__(self, pids, labels, embeddings, pid_to_index):\n",
    "        \"\"\"\n",
    "        pids: list[str]               - protein ids\n",
    "        labels: np.ndarray or sparse  - multi-hot labels\n",
    "        embeddings: np.ndarray/mmap   - (N, D)\n",
    "        pid_to_index: dict[str, int]\n",
    "        \"\"\"\n",
    "        self.pids = pids\n",
    "        self.labels = labels\n",
    "        self.embeddings = embeddings\n",
    "        self.pid_to_index = pid_to_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pid = self.pids[idx]\n",
    "\n",
    "        # embedding\n",
    "        emb_idx = self.pid_to_index.get(pid)\n",
    "        if emb_idx is None:\n",
    "            raise KeyError(f\"Embedding not found for protein {pid}\")\n",
    "\n",
    "        embed = self.embeddings[emb_idx]\n",
    "\n",
    "        # label\n",
    "        if hasattr(self.labels, \"toarray\"):  # sparse matrix\n",
    "            label = self.labels[idx].toarray().ravel()\n",
    "        else:\n",
    "            label = self.labels[idx]\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(embed).float(),\n",
    "            torch.from_numpy(label).float()\n",
    "        )\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, pids, embeddings, pid_to_index):\n",
    "        self.pids = pids\n",
    "        self.embeddings = embeddings\n",
    "        self.pid_to_index = pid_to_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pid = self.pids[idx]\n",
    "        emb_idx = self.pid_to_index.get(pid)\n",
    "\n",
    "        if emb_idx is None:\n",
    "            raise KeyError(f\"Embedding not found for protein {pid}\")\n",
    "\n",
    "        embed = self.embeddings[emb_idx]\n",
    "        return torch.from_numpy(embed).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:50:22.947744Z",
     "iopub.status.busy": "2025-12-14T15:50:22.947494Z",
     "iopub.status.idle": "2025-12-14T15:50:22.976795Z",
     "shell.execute_reply": "2025-12-14T15:50:22.976277Z",
     "shell.execute_reply.started": "2025-12-14T15:50:22.947722Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim=1280, num_classes=3000):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "def get_improved_model(num_classes):\n",
    "    return SimpleMLP(input_dim=1280, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:50:22.977774Z",
     "iopub.status.busy": "2025-12-14T15:50:22.977517Z",
     "iopub.status.idle": "2025-12-14T15:50:22.996416Z",
     "shell.execute_reply": "2025-12-14T15:50:22.995848Z",
     "shell.execute_reply.started": "2025-12-14T15:50:22.977753Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#VISUALIZATION\n",
    "def plot_losses_and_scores(train_losses, val_losses, train_scores, val_scores, aspect_name):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Loss\n",
    "    axes[0].plot(train_losses, label='Train Loss')\n",
    "    axes[0].plot(val_losses, label='Val Loss')\n",
    "    axes[0].set_title(f'{aspect_name} - Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # F1\n",
    "    axes[1].plot(train_scores, label='Train F1')\n",
    "    axes[1].plot(val_scores, label='Val F1')\n",
    "    axes[1].set_title(f'{aspect_name} - Micro F1')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('F1')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{aspect_name}_training_curves.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "def train(\n",
    "    aspect_name,\n",
    "    model,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    num_epochs,\n",
    "    num_classes,\n",
    "    lr,\n",
    "    grad_clip=1.0\n",
    "):\n",
    "    model = model.to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=2\n",
    "    )\n",
    "\n",
    "    f1_metric = MultilabelF1Score(\n",
    "        num_labels=num_classes,\n",
    "        threshold=0.05,\n",
    "        average='micro'\n",
    "    ).to(device)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_scores, val_scores = [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # ================= TRAIN =================\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * X.size(0)\n",
    "            all_preds.append(torch.sigmoid(logits).detach())\n",
    "            all_labels.append(y)\n",
    "\n",
    "        train_loss = total_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        all_preds = torch.vstack(all_preds)\n",
    "        all_labels = torch.vstack(all_labels)\n",
    "        train_f1 = f1_metric(all_preds, all_labels).item()\n",
    "        train_scores.append(train_f1)\n",
    "\n",
    "        # ================= VALID =================\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in valid_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                logits = model(X)\n",
    "                loss = loss_fn(logits, y)\n",
    "\n",
    "                val_loss += loss.item() * X.size(0)\n",
    "                all_preds.append(torch.sigmoid(logits))\n",
    "                all_labels.append(y)\n",
    "\n",
    "        val_loss /= len(valid_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        all_preds = torch.vstack(all_preds)\n",
    "        all_labels = torch.vstack(all_labels)\n",
    "        val_f1 = f1_metric(all_preds, all_labels).item()\n",
    "        val_scores.append(val_f1)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(\n",
    "            f\"[{aspect_name}] Epoch {epoch:02d}/{num_epochs} | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | Train F1: {train_f1:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f} | Val F1: {val_f1:.4f}\"\n",
    "        )\n",
    "\n",
    "    plot_losses_and_scores(\n",
    "        train_losses,\n",
    "        val_losses,\n",
    "        train_scores,\n",
    "        val_scores,\n",
    "        aspect_name\n",
    "    )\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:50:22.997557Z",
     "iopub.status.busy": "2025-12-14T15:50:22.997228Z",
     "iopub.status.idle": "2025-12-14T15:50:23.017669Z",
     "shell.execute_reply": "2025-12-14T15:50:23.017143Z",
     "shell.execute_reply.started": "2025-12-14T15:50:22.997534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ASPECTS = ['C', 'F', 'P']\n",
    "ASPECT_NAMES = {'C': 'Cellular Component (CCO)', 'F': 'Molecular Function (MFO)', 'P': 'Biological Process (BPO)'}\n",
    "aspect_models = {}\n",
    "aspect_mlbs = {}\n",
    "def train_aspect_model(aspect_name, seed=42):\n",
    "    global aspect_models, aspect_mlbs\n",
    "\n",
    "    print(f\"\\n===== Training model for aspect {aspect_name} =====\")\n",
    "\n",
    "    # Reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    aspect_df = train_terms_df[train_terms_df['aspect'] == aspect_name]\n",
    "\n",
    "    # Group GO terms by protein\n",
    "    protein_2_terms = (\n",
    "        aspect_df.groupby('EntryID')['term']\n",
    "        .apply(list)\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    # Filter valid proteins\n",
    "    pid_train = [\n",
    "        pid for pid in train_sequences\n",
    "        if pid in embeddings_dict and pid in protein_2_terms\n",
    "    ]\n",
    "\n",
    "    labels_list = [protein_2_terms[pid] for pid in pid_train]\n",
    "\n",
    "    # Multi-label binarizer\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    y_train_labels = mlb.fit_transform(labels_list)\n",
    "\n",
    "    aspect_mlbs[aspect_name] = mlb\n",
    "    num_classes = len(mlb.classes_)\n",
    "\n",
    "    print(\n",
    "        f\"{aspect_name} | Proteins: {len(pid_train)} | \"\n",
    "        f\"GO terms: {num_classes}\"\n",
    "    )\n",
    "\n",
    "    # Dataset\n",
    "    dataset = ProtDataset(pid_train, y_train_labels, embeddings_dict)\n",
    "\n",
    "    train_size = int(0.9 * len(dataset))\n",
    "    valid_size = len(dataset) - train_size\n",
    "\n",
    "    train_part, valid_part = random_split(\n",
    "        dataset,\n",
    "        [train_size, valid_size],\n",
    "        generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_part,\n",
    "        batch_size=128,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_part,\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    model = train(\n",
    "        aspect_name=aspect_name,\n",
    "        model=get_improved_model(num_classes),\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=valid_loader,\n",
    "        num_epochs=30,\n",
    "        num_classes=num_classes,\n",
    "        lr=1e-3\n",
    "    )\n",
    "\n",
    "    aspect_models[aspect_name] = model\n",
    "\n",
    "    # Cleanup\n",
    "    del dataset, train_part, valid_part, y_train_labels\n",
    "    torch.cuda.empty_cache()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    return model, mlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:50:23.018604Z",
     "iopub.status.busy": "2025-12-14T15:50:23.018357Z",
     "iopub.status.idle": "2025-12-14T15:58:37.424190Z",
     "shell.execute_reply": "2025-12-14T15:58:37.423517Z",
     "shell.execute_reply.started": "2025-12-14T15:50:23.018588Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for aspect in ASPECTS:\n",
    "    train_aspect_model(aspect)\n",
    "    torch.save({\n",
    "        \"model\": aspect_models[aspect].state_dict(),\n",
    "    }, f\"checkpoint-{aspect}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:58:37.425450Z",
     "iopub.status.busy": "2025-12-14T15:58:37.425162Z",
     "iopub.status.idle": "2025-12-14T15:58:37.433288Z",
     "shell.execute_reply": "2025-12-14T15:58:37.432555Z",
     "shell.execute_reply.started": "2025-12-14T15:58:37.425417Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(threshold=0.02, min_predictions=25):\n",
    "    \"\"\"\n",
    "    Generate predictions for test proteins using trained aspect-specific models.\n",
    "    \"\"\"\n",
    "\n",
    "    pid_test = [pid for pid in test_sequences if pid in embeddings_dict]\n",
    "\n",
    "    test_dataset = TestDataSet(pid_test, embeddings_dict)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    submission_list = []\n",
    "\n",
    "    for aspect in ASPECTS:\n",
    "        print(f\"\\n=== Predicting aspect {aspect} ===\")\n",
    "\n",
    "        model = aspect_models[aspect].to(device)\n",
    "        mlb = aspect_mlbs[aspect]\n",
    "        model.eval()\n",
    "\n",
    "        pid_offset = 0\n",
    "\n",
    "        for batch_embeds in tqdm(test_loader, desc=f\"Predicting ({aspect})\"):\n",
    "            batch_embeds = batch_embeds.to(device, non_blocking=True)\n",
    "            batch_size = batch_embeds.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(batch_embeds)\n",
    "                probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                protein_id = pid_test[pid_offset + i]\n",
    "                scores = probs[i]\n",
    "\n",
    "                # Threshold filtering\n",
    "                term_indices = np.where(scores >= threshold)[0]\n",
    "\n",
    "                # Ensure minimum predictions\n",
    "                if len(term_indices) < min_predictions:\n",
    "                    term_indices = np.argsort(scores)[-min_predictions:][::-1]\n",
    "\n",
    "                for idx in term_indices:\n",
    "                    submission_list.append({\n",
    "                        'pid': protein_id,\n",
    "                        'term': mlb.classes_[idx],\n",
    "                        'p': float(scores[idx])\n",
    "                    })\n",
    "\n",
    "            pid_offset += batch_size\n",
    "\n",
    "            del batch_embeds, logits, probs\n",
    "            if pid_offset % 5000 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    submission_df = pd.DataFrame(submission_list)\n",
    "    print(f\"\\nTotal predictions: {len(submission_df)}\")\n",
    "\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:58:37.434299Z",
     "iopub.status.busy": "2025-12-14T15:58:37.434033Z",
     "iopub.status.idle": "2025-12-14T15:58:37.452954Z",
     "shell.execute_reply": "2025-12-14T15:58:37.452480Z",
     "shell.execute_reply.started": "2025-12-14T15:58:37.434277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_aspect_num_classes(aspect_name):\n",
    "    aspect_df = train_terms_df[train_terms_df['aspect'] == aspect_name]\n",
    "\n",
    "    protein_2_terms = (\n",
    "        aspect_df.groupby('EntryID')['term']\n",
    "        .apply(list)\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    pid_train = [\n",
    "        pid for pid in train_sequences\n",
    "        if pid in embeddings_dict and pid in protein_2_terms\n",
    "    ]\n",
    "\n",
    "    labels_list = [protein_2_terms[pid] for pid in pid_train]\n",
    "\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    mlb.fit(labels_list)\n",
    "\n",
    "    return len(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:58:37.453806Z",
     "iopub.status.busy": "2025-12-14T15:58:37.453597Z",
     "iopub.status.idle": "2025-12-14T16:19:23.693411Z",
     "shell.execute_reply": "2025-12-14T16:19:23.691962Z",
     "shell.execute_reply.started": "2025-12-14T15:58:37.453786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for aspect in ASPECTS:\n",
    "    print(f\"Loading model for aspect {aspect}\")\n",
    "\n",
    "    checkpoint_path = f\"/kaggle/working/checkpoint-{aspect}.pth\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "\n",
    "    num_classes = get_aspect_num_classes(aspect)\n",
    "\n",
    "    model = get_improved_model(num_classes)\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    aspect_models[aspect] = model\n",
    "\n",
    "combined_submission_df = predict(threshold=0.02)\n",
    "\n",
    "propagated_df = propagate_predictions(\n",
    "    combined_submission_df,\n",
    "    go_parents\n",
    ")\n",
    "\n",
    "cleaned_df = apply_negative_propagation(\n",
    "    propagated_df,\n",
    "    negative_keys\n",
    ")\n",
    "\n",
    "final_df = add_goa_ground_truth(\n",
    "    cleaned_df,\n",
    "    goa_positive_df\n",
    ")\n",
    "\n",
    "final_df.to_csv(\n",
    "    \"submission.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    "    header=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14875579,
     "isSourceIdPinned": false,
     "sourceId": 116062,
     "sourceType": "competition"
    },
    {
     "datasetId": 9020260,
     "sourceId": 14152605,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9021302,
     "sourceId": 14154019,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
